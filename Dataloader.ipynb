{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Volumes/SD/Data/semantic_annotations/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find Json file of a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [ x for x in os.listdir(root) if x.endswith(\"json\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66261"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load and parse a single Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root + json_files[1]) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_type = []\n",
    "ele_coor = []\n",
    "for c in data['children']:\n",
    "    ele_type.append(c['componentLabel'])\n",
    "    ele_coor.append(c['bounds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Process all J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ele(file_names, root, max_element_num = 1000):\n",
    "    all_ele_type = []\n",
    "    all_ele_coor = []\n",
    "    for f in file_names:\n",
    "        with open(root + f) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            if not max_element_num < len(data['children']):\n",
    "                ele_type = []\n",
    "                ele_coor = []\n",
    "                for c in data['children']:\n",
    "                    ele_type.append(c['componentLabel'])\n",
    "                    ele_coor.append(c['bounds'])\n",
    "                all_ele_type.append(ele_type)\n",
    "                all_ele_coor.append(ele_coor)\n",
    "    return (all_ele_type, all_ele_coor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, c = read_ele(json_files, root, max_element_num = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. One-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Unique Type, number of unique types, element to int\n",
    "uni_types = list(set([x for ele in t for x in ele]))\n",
    "max_len = len(uni_types)\n",
    "ele_dict = {v:i for i, v in enumerate(uni_types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "def onehot_encoder(ele, ele_dict, max_len):\n",
    "    l = [0] * max_len\n",
    "    idx = ele_dict[ele]\n",
    "    l[idx] = 1\n",
    "    return l\n",
    "onehot_encoder('Image', ele_dict, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Process All the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = [x for x in t if x != []]\n",
    "c_ = [x for x in c if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_all = []\n",
    "count = 0\n",
    "for ele, coor in zip(t_,c_):\n",
    "    ele_enc = [onehot_encoder(e, ele_dict, max_len) for e in ele]\n",
    "    ele_merge = [np.array(e+c) for e,c in zip(ele_enc, coor)]\n",
    "    fill_len = 9 - len(ele)\n",
    "    try:\n",
    "        if fill_len > 0:\n",
    "            ele_fill = np.zeros((fill_len,max_len+4))\n",
    "            ele_merge = np.concatenate((ele_merge, ele_fill))\n",
    "    except:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    ele_all.append(ele_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(np.array(ele_all))\n",
    "y = torch.ones(x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x, y)\n",
    "data_loader = DataLoader(dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
